{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2c196ec0-bf7b-4b2d-8709-96b0cb478361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import optuna\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pymorphy3\n",
    "from catboost import CatBoostClassifier, Pool, cv\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import stop_words\n",
    "import string\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "random_state = 52\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(style='darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "06cdec62-70b6-4d2f-b1c2-b39315fdf48d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>m.kp.md</td>\n",
       "      <td>Экс-министр экономики Молдовы - главе МИДЭИ, ц...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>www.kp.by</td>\n",
       "      <td>Эта песня стала известна многим телезрителям б...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>fanserials.tv</td>\n",
       "      <td>Банши 4 сезон 2 серия Бремя красоты смотреть о...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>colorbox.spb.ru</td>\n",
       "      <td>Не Беси Меня Картинки</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>tula-sport.ru</td>\n",
       "      <td>В Новомосковске сыграют следж-хоккеисты алекси...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID              url                                              title  \\\n",
       "0   0          m.kp.md  Экс-министр экономики Молдовы - главе МИДЭИ, ц...   \n",
       "1   1        www.kp.by  Эта песня стала известна многим телезрителям б...   \n",
       "2   2    fanserials.tv  Банши 4 сезон 2 серия Бремя красоты смотреть о...   \n",
       "3   3  colorbox.spb.ru                              Не Беси Меня Картинки   \n",
       "4   4    tula-sport.ru  В Новомосковске сыграют следж-хоккеисты алекси...   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6555dc08-bb7c-4e01-9461-1af3490d8404",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(columns=['ID'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "bedff4f6-cec2-4933-93c5-8ad3ac50dd21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>label</th>\n",
       "      <th>text_title</th>\n",
       "      <th>text_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m.kp.md</td>\n",
       "      <td>Экс-министр экономики Молдовы - главе МИДЭИ, ц...</td>\n",
       "      <td>0</td>\n",
       "      <td>экс министр экономики молдовы главе мидэи цель...</td>\n",
       "      <td>m kp md</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>www.kp.by</td>\n",
       "      <td>Эта песня стала известна многим телезрителям б...</td>\n",
       "      <td>0</td>\n",
       "      <td>эта песня стала известна многим телезрителям б...</td>\n",
       "      <td>www kp by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fanserials.tv</td>\n",
       "      <td>Банши 4 сезон 2 серия Бремя красоты смотреть о...</td>\n",
       "      <td>0</td>\n",
       "      <td>банши 4 сезон 2 серия бремя красоты смотреть о...</td>\n",
       "      <td>fanserials tv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>colorbox.spb.ru</td>\n",
       "      <td>Не Беси Меня Картинки</td>\n",
       "      <td>0</td>\n",
       "      <td>не беси меня картинки</td>\n",
       "      <td>colorbox spb ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tula-sport.ru</td>\n",
       "      <td>В Новомосковске сыграют следж-хоккеисты алекси...</td>\n",
       "      <td>0</td>\n",
       "      <td>в новомосковске сыграют следж хоккеисты алекси...</td>\n",
       "      <td>tula-sport ru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               url                                              title  label  \\\n",
       "0          m.kp.md  Экс-министр экономики Молдовы - главе МИДЭИ, ц...      0   \n",
       "1        www.kp.by  Эта песня стала известна многим телезрителям б...      0   \n",
       "2    fanserials.tv  Банши 4 сезон 2 серия Бремя красоты смотреть о...      0   \n",
       "3  colorbox.spb.ru                              Не Беси Меня Картинки      0   \n",
       "4    tula-sport.ru  В Новомосковске сыграют следж-хоккеисты алекси...      0   \n",
       "\n",
       "                                          text_title         text_url  \n",
       "0  экс министр экономики молдовы главе мидэи цель...          m kp md  \n",
       "1  эта песня стала известна многим телезрителям б...        www kp by  \n",
       "2  банши 4 сезон 2 серия бремя красоты смотреть о...    fanserials tv  \n",
       "3                              не беси меня картинки  colorbox spb ru  \n",
       "4  в новомосковске сыграют следж хоккеисты алекси...    tula-sport ru  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "russian_stopwords = stop_words.get_stop_words('ru')\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    return ''.join([ch if ch not in string.punctuation else ' ' for ch in text])\n",
    "    \n",
    "def remove_numbers(text):\n",
    "    return ''.join([i if not i.isdigit() else ' ' for i in text])\n",
    "\n",
    "def remove_multiple_spaces(text):\n",
    "    return re.sub(r'\\s+', ' ', text, flags=re.I)\n",
    "\n",
    "prep_title = [remove_multiple_spaces(remove_punctuation(text.lower())) for text in train_df['title'].astype('str')]\n",
    "train_df['text_title'] = prep_title\n",
    "train_df['text_url'] = train_df['url'].apply(lambda x: ' '.join(x.split('.')))\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f7ef849a-6e12-4710-becd-8045c9c182c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = ['porn', 'sex', 'erotic', 'adults', 'xxx', 'naked', 'intimate', 'hardcore', 'lesbians', 'fetish', 'masturbation', \n",
    "            'anal', 'oral', 'pornstars', 'sexual', 'sperm', 'swingers', 'bondage', 'bdsm', 'vibrator', 'cunnilingus', 'dildo',\n",
    "            'ejaculation', 'hot', 'guy', 'xvideos', 'blowjob', 'cumshot', 'incest', 'tits', 'fuck',\n",
    "            'порно', 'секс', 'эротика', 'взрослый', 'голый', 'интим', 'жесткий', 'лесбиянка', 'фетиш', 'дрочка', 'анал',\n",
    "            'оральный', 'порнозвезда', 'сперма', 'мастурбация', 'групповой', 'свингеры', 'бондаж', 'бдсм', 'вибратор', 'кунилингус',\n",
    "            'фото', 'инцест', 'волосатый', 'минет', 'домашний', 'мамочка', 'зрелый', 'молоденький', 'сучка', 'групповуха',\n",
    "            'хардкор', 'попка', 'сосать', 'milfs', 'moms', 'cocks', 'pussy', 'nudes', 'sexsy', 'mommy', 'videos',\n",
    "             'хуй', 'nude', 'video', 'sexy', 'porno', 'кончать', 'член', 'оргазм', 'привязать', '24xxx', 'грудастый', 'por', 'sexo',\n",
    "             'sweet', 'camshooker', 'долбиться', 'блондинка', 'gay', 'big', 'butts', 'teens', 'pornhub', '18yo', 'creampied', 'тёлка',\n",
    "             'раздеться', 'красотка', 'страпонить', 'горячий', 'biqle', 'девка', 'писька', 'задница', 'хоумвидео', 'шлюшка', 'трахаться',\n",
    "             'трахать', 'эротический', 'эскорт', 'пизда', 'дрючить', 'небритый', 'дрочить', 'клитор', 'стояк', 'отсосать', 'шлюха',\n",
    "             'бритый', 'жопа']\n",
    "\n",
    "morph = pymorphy3.MorphAnalyzer()\n",
    "\n",
    "stop_words = [morph.parse(word)[0].normal_form for word in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5ec076d1-8648-4cda-a9f7-f364d3959713",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['url_len'] = train_df.url.str.len()\n",
    "train_df['title_len'] = train_df.title.str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9166b211-e1a7-452b-9e0f-eb7226679f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trigrams(text):\n",
    "    trigrams = [text[i:i+3] for i in range(len(text) - 2)]\n",
    "    return trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0c5271f3-eb3f-4110-99e9-a8900e53d2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_title(train_df, train=True):\n",
    "    morph = pymorphy3.MorphAnalyzer()\n",
    "    \n",
    "    lemm_texts_list = []\n",
    "    lemm_trigram = []\n",
    "    for text in tqdm(train_df['text_title']):\n",
    "        text_lem = [morph.parse(word)[0].normal_form for word in text.split(' ') if word not in russian_stopwords]\n",
    "\n",
    "        \n",
    "        # if train and len(text_lem) <= 0:\n",
    "        #     lemm_texts_list.append('')\n",
    "        #     continue\n",
    "        lemm_trigram.append(generate_trigrams(text))   \n",
    "        lemm_texts_list.append(' '.join(text_lem))\n",
    "\n",
    "        \n",
    "        \n",
    "    train_df['text_lemm'] = lemm_texts_list\n",
    "    # if train:\n",
    "    #     train_df = train_df[train_df['text_lemm'] != '']\n",
    "        \n",
    "    train_df['trigram_title'] = lemm_trigram\n",
    "    train_df['stop_count_title'] = train_df['text_lemm'].apply(lambda x: sum(1 for word in x.split(' ') if word in stop_words))\n",
    "    train_df['stop_count_title'] += train_df['trigram_title'].apply(lambda x: sum(1 for word in x if word in ['sex', 'por', 'xxx',\n",
    "                                                                                                         'hdx', 'orn', 'gir',\n",
    "                                                                                                         'irl', 'rls', 'vka',\n",
    "                                                                                                         'dev', 'rno', 'sek'\n",
    "                                                                                                         'kis','adu', 'dul',\n",
    "                                                                                                         'ebu', 'boo', 'oob',\n",
    "                                                                                                         'obs', 'пор', 'орн',\n",
    "                                                                                                         'рно', 'сек', 'екс']))\n",
    "    \n",
    "    train_df.drop(columns=['text_title'], inplace=True)\n",
    "    train_df.drop(columns=['title'], inplace=True)\n",
    "    train_df.drop(columns=['trigram_title'], inplace=True)\n",
    "    \n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0b49bc3d-3a6c-4de1-8156-0b30546e0319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_url(train_df):\n",
    "    lemm_texts_list = []\n",
    "    lemm_trigram = []\n",
    "    for text in tqdm(train_df['text_url']):\n",
    "        text_lem = [word for word in text.split(' ') if word not in ['www', 'by', 'ru', 'com', 'ua', 'net', 'org']]\n",
    "        \n",
    "        lemm_texts_list.append(' '.join(text_lem))\n",
    "\n",
    "        lemm_trigram.append(generate_trigrams(text))\n",
    "        \n",
    "    train_df['lemm_url'] = lemm_texts_list\n",
    "    train_df['trigram_url'] = lemm_trigram\n",
    "    train_df['stop_count_url'] = train_df['trigram_url'].apply(lambda x: sum(1 for word in x for s in word.split('-') if s in \n",
    "                                                               ['sex', 'por', 'xxx',\n",
    "                                                                'hdx', 'orn', 'gir',\n",
    "                                                                'irl', 'rls', 'vka',\n",
    "                                                                'dev', 'rno', 'sek'\n",
    "                                                                'kis', '365',\n",
    "                                                                'adu', 'dul', 'ebu',\n",
    "                                                                'ful', 'boo', 'oob',\n",
    "                                                                'obs', 'lov', 'ove']))\n",
    "    train_df.drop(columns=['text_url'], inplace=True)\n",
    "    train_df.drop(columns=['url'], inplace=True)\n",
    "    train_df.drop(columns=['trigram_url'], inplace=True)\n",
    "\n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "97c5fa78-9370-4656-8667-7e28caa2765c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df\n",
    "y = train_df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=random_state, test_size=0.25, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=random_state, test_size=0.25, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "35c3c3b2-fd62-4b4c-b2cd-816bf2e53efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 101481/101481 [01:22<00:00, 1224.36it/s]\n",
      "100%|███████████████████████████████████| 76110/76110 [01:04<00:00, 1182.49it/s]\n",
      "100%|███████████████████████████████████| 25371/25371 [00:22<00:00, 1141.30it/s]\n",
      "100%|███████████████████████████████████| 33828/33828 [00:27<00:00, 1244.01it/s]\n"
     ]
    }
   ],
   "source": [
    "X_f = pd.concat([X_train, X_val])\n",
    "y_f = pd.concat([y_train, y_val])\n",
    "X_f = vectorize_title(X_f)\n",
    "\n",
    "X_train = vectorize_title(X_train)\n",
    "X_val = vectorize_title(X_val, train=False)\n",
    "X_test = vectorize_title(X_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e1755e8e-8749-425e-8ca5-217a5ea3a68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 25371/25371 [00:00<00:00, 244247.91it/s]\n",
      "100%|██████████████████████████████████| 76110/76110 [00:01<00:00, 55244.88it/s]\n",
      "100%|█████████████████████████████████| 33828/33828 [00:00<00:00, 251636.37it/s]\n",
      "100%|███████████████████████████████| 101481/101481 [00:00<00:00, 296396.84it/s]\n"
     ]
    }
   ],
   "source": [
    "y_val = X_val['label']\n",
    "X_val = vectorize_url(X_val).drop(columns=['label'])\n",
    "\n",
    "y_train = X_train['label']\n",
    "X_train = vectorize_url(X_train).drop(columns=['label'])\n",
    "\n",
    "y_test = X_test['label']\n",
    "X_test = vectorize_url(X_test).drop(columns=['label'])\n",
    "\n",
    "y_f = X_f['label']\n",
    "X_f = vectorize_url(X_f).drop(columns=['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "10663994-357f-473c-9a88-550b26acd314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(train_pool, test_pool, **kwargs):\n",
    "    model = CatBoostClassifier(random_seed=random_state, iterations=1000,\n",
    "                               eval_metric='TotalF1', **kwargs)\n",
    "    \n",
    "    return model.fit(train_pool, eval_set=test_pool, \n",
    "                     verbose=300, use_best_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3f4238f5-1dbf-4feb-aab9-f44fc79cdc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pool = Pool(data=X_train, label=y_train, \n",
    "                  text_features=['text_lemm', 'lemm_url',])\n",
    "valid_pool = Pool(data=X_val, label=y_val, \n",
    "                  text_features=['text_lemm', 'lemm_url',])\n",
    "test_pool = Pool(data=X_test, label=y_test, \n",
    "                  text_features=['text_lemm', 'lemm_url',])\n",
    "\n",
    "Xf_pool = Pool(data=X_f, label=y_f, \n",
    "                  text_features=['text_lemm', 'lemm_url',])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc9be8cf-d553-4c6c-963c-96199e4ee786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9355192\ttest: 0.9321189\tbest: 0.9321189 (0)\ttotal: 214ms\tremaining: 3m 34s\n",
      "300:\tlearn: 0.9948734\ttest: 0.9871869\tbest: 0.9872833 (289)\ttotal: 1m 14s\tremaining: 2m 53s\n",
      "600:\tlearn: 0.9983336\ttest: 0.9880139\tbest: 0.9880139 (596)\ttotal: 2m 30s\tremaining: 1m 39s\n",
      "900:\tlearn: 0.9995842\ttest: 0.9883040\tbest: 0.9883500 (878)\ttotal: 3m 46s\tremaining: 24.9s\n",
      "999:\tlearn: 0.9995842\ttest: 0.9884959\tbest: 0.9884959 (999)\ttotal: 4m 12s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.9884958653\n",
      "bestIteration = 999\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9567634342186534"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = fit_model(train_pool, valid_pool, learning_rate=0.3,\n",
    "                  dictionaries = [{\n",
    "                      'dictionary_id':'Word',\n",
    "                      'max_dictionary_size': '50000'\n",
    "                  }],\n",
    "                 feature_calcers = ['BoW:top_tokens_count=10000'])\n",
    "y_pred = model.predict(test_pool)\n",
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b788e294-26a3-41b4-8ecf-8ff0724027f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9536559\ttest: 0.9549840\tbest: 0.9549840 (0)\ttotal: 297ms\tremaining: 4m 56s\n",
      "300:\tlearn: 0.9973711\ttest: 0.9935138\tbest: 0.9935138 (296)\ttotal: 1m 37s\tremaining: 3m 46s\n",
      "600:\tlearn: 0.9993292\ttest: 0.9941445\tbest: 0.9941445 (599)\ttotal: 3m 12s\tremaining: 2m 7s\n",
      "900:\tlearn: 0.9995267\ttest: 0.9944123\tbest: 0.9944718 (712)\ttotal: 4m 47s\tremaining: 31.6s\n",
      "999:\tlearn: 0.9995563\ttest: 0.9943541\tbest: 0.9944718 (712)\ttotal: 5m 19s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.9944717698\n",
      "bestIteration = 712\n",
      "\n",
      "Shrink model to first 713 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9774654712866488"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = fit_model(Xf_pool, test_pool, learning_rate=0.48,\n",
    "                  dictionaries = [{\n",
    "                      'dictionary_id':'Word',\n",
    "                      'max_dictionary_size': '50000'\n",
    "                  }],\n",
    "                 feature_calcers = ['BoW:top_tokens_count=10000'])\n",
    "y_pred = model.predict(test_pool)\n",
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9275e608-70c5-4fce-901c-79371ab57e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url_len</th>\n",
       "      <th>title_len</th>\n",
       "      <th>text_lemm</th>\n",
       "      <th>stop_count_title</th>\n",
       "      <th>lemm_url</th>\n",
       "      <th>stop_count_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>126744</th>\n",
       "      <td>7</td>\n",
       "      <td>83.0</td>\n",
       "      <td>ответ mail ru индивидуализация помочь пожалуйс...</td>\n",
       "      <td>0</td>\n",
       "      <td>mail</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50620</th>\n",
       "      <td>12</td>\n",
       "      <td>88.0</td>\n",
       "      <td>вакуумный усилитель тормоз toyota gaia acm10 a...</td>\n",
       "      <td>0</td>\n",
       "      <td>baza drom</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90787</th>\n",
       "      <td>10</td>\n",
       "      <td>95.0</td>\n",
       "      <td>роздравнадзор сообщать отмена государственный ...</td>\n",
       "      <td>0</td>\n",
       "      <td>gmpnews</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134973</th>\n",
       "      <td>14</td>\n",
       "      <td>45.0</td>\n",
       "      <td>мягкий игрушка джек рассесть терьер babytoy</td>\n",
       "      <td>0</td>\n",
       "      <td>babytoy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94159</th>\n",
       "      <td>30</td>\n",
       "      <td>141.0</td>\n",
       "      <td>электробатарея экономный отопление продажа цен...</td>\n",
       "      <td>0</td>\n",
       "      <td>ekonomnoe-otoplenie uaprom</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4324</th>\n",
       "      <td>15</td>\n",
       "      <td>23.0</td>\n",
       "      <td>are not gay porn please</td>\n",
       "      <td>4</td>\n",
       "      <td>kindprotect xyz</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9116</th>\n",
       "      <td>18</td>\n",
       "      <td>67.0</td>\n",
       "      <td>вакансия ведущий разработчик пермь работа ивс ...</td>\n",
       "      <td>0</td>\n",
       "      <td>ekaterinburg hh</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1172</th>\n",
       "      <td>17</td>\n",
       "      <td>54.0</td>\n",
       "      <td>attractive demise 4 vore fan page 9 eggporncomics</td>\n",
       "      <td>2</td>\n",
       "      <td>eggporncomics</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79031</th>\n",
       "      <td>11</td>\n",
       "      <td>36.0</td>\n",
       "      <td>тоо quantom проверка контрагент</td>\n",
       "      <td>0</td>\n",
       "      <td>pk uchet kz</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68477</th>\n",
       "      <td>9</td>\n",
       "      <td>79.0</td>\n",
       "      <td>семимесячный ребёночек неделя неделя получатьс...</td>\n",
       "      <td>0</td>\n",
       "      <td>m baby</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76110 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        url_len  title_len                                          text_lemm  \\\n",
       "126744        7       83.0  ответ mail ru индивидуализация помочь пожалуйс...   \n",
       "50620        12       88.0  вакуумный усилитель тормоз toyota gaia acm10 a...   \n",
       "90787        10       95.0  роздравнадзор сообщать отмена государственный ...   \n",
       "134973       14       45.0        мягкий игрушка джек рассесть терьер babytoy   \n",
       "94159        30      141.0  электробатарея экономный отопление продажа цен...   \n",
       "...         ...        ...                                                ...   \n",
       "4324         15       23.0                            are not gay porn please   \n",
       "9116         18       67.0  вакансия ведущий разработчик пермь работа ивс ...   \n",
       "1172         17       54.0  attractive demise 4 vore fan page 9 eggporncomics   \n",
       "79031        11       36.0                    тоо quantom проверка контрагент   \n",
       "68477         9       79.0  семимесячный ребёночек неделя неделя получатьс...   \n",
       "\n",
       "        stop_count_title                    lemm_url  stop_count_url  \n",
       "126744                 0                        mail               0  \n",
       "50620                  0                   baza drom               0  \n",
       "90787                  0                     gmpnews               0  \n",
       "134973                 0                     babytoy               0  \n",
       "94159                  0  ekonomnoe-otoplenie uaprom               0  \n",
       "...                  ...                         ...             ...  \n",
       "4324                   4             kindprotect xyz               0  \n",
       "9116                   0             ekaterinburg hh               0  \n",
       "1172                   2               eggporncomics               2  \n",
       "79031                  0                 pk uchet kz               0  \n",
       "68477                  0                      m baby               0  \n",
       "\n",
       "[76110 rows x 6 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d0fcbf9a-5276-4a2b-8d72-a0d263c3a86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "test_df.head()\n",
    "test_df = test_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a4dab421-82c1-4ec5-8273-fe177bde7579",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 165378/165378 [02:17<00:00, 1198.82it/s]\n",
      "100%|███████████████████████████████| 165378/165378 [00:01<00:00, 106827.55it/s]\n"
     ]
    }
   ],
   "source": [
    "morph = pymorphy3.MorphAnalyzer()\n",
    "\n",
    "prep_title = [remove_multiple_spaces(remove_numbers(remove_punctuation(text.lower()))) for text in test_df['title'].astype('str')]\n",
    "test_df['text_title'] = prep_title\n",
    "test_df['text_url'] = test_df['url'].apply(lambda x: ' '.join(x.split('.')))\n",
    "\n",
    "test_df['url_len'] = test_df.url.str.len()\n",
    "test_df['title_len'] = test_df.title.str.len()\n",
    "#test_df['count_word'] = test_df['text_title'].apply(lambda x: len(x.split(' ')))\n",
    "lemm_trigram_t = []\n",
    "lemm_texts_list = []\n",
    "for text in tqdm(test_df['text_title']):\n",
    "    text_lem = [morph.parse(word)[0].normal_form for word in text.split(' ') if word not in russian_stopwords]\n",
    "    lemm_texts_list.append(' '.join(text_lem))\n",
    "    lemm_trigram_t.append(generate_trigrams(text))\n",
    "\n",
    "test_df['text_lemm'] = lemm_texts_list\n",
    "#test_df = test_df[test_df['text_lemm'] != '']\n",
    "\n",
    "lemm_texts_list = []\n",
    "lemm_trigram = []\n",
    "for text in tqdm(test_df['text_url']):\n",
    "    text_lem = [word for word in text.split(' ') if word not in ['www', 'by', 'ru', 'com', 'ua', 'net', 'org']]\n",
    "        \n",
    "    lemm_texts_list.append(' '.join(text_lem))\n",
    "    trigram = lemm_trigram.append(generate_trigrams(text))\n",
    "\n",
    "test_df['trigram_title'] = lemm_trigram\n",
    "test_df['lemm_url'] = lemm_texts_list\n",
    "test_df['trigram_url'] = lemm_trigram\n",
    "test_df['stop_count_title'] = test_df['text_lemm'].apply(lambda x: sum(1 for word in x.split(' ') if word in stop_words))\n",
    "\n",
    "test_df['stop_count_title'] += test_df['trigram_title'].apply(lambda x: sum(1 for word in x if word in ['sex', 'por', 'xxx',\n",
    "                                                                                                         'hdx', 'orn', 'gir',\n",
    "                                                                                                         'irl', 'rls', 'vka',\n",
    "                                                                                                         'dev', 'rno', 'sek'\n",
    "                                                                                                         'kis','adu', 'dul',\n",
    "                                                                                                         'ebu', 'boo', 'oob',\n",
    "                                                                                                         'obs', 'пор', 'орн',\n",
    "                                                                                                         'рно', 'сек', 'екс']))\n",
    "test_df['stop_count_url'] = test_df['trigram_url'].apply(lambda x: sum(1 for word in x for s in word.split('-') if s in \n",
    "                                                               ['sex', 'por', 'xxx',\n",
    "                                                                'hdx', 'orn', 'gir',\n",
    "                                                                'irl', 'rls', 'vka',\n",
    "                                                                'dev', 'rno', 'sek'\n",
    "                                                                'kis', '365',\n",
    "                                                                'adu', 'dul', 'ebu',\n",
    "                                                                'ful', 'boo', 'oob',\n",
    "                                                                'obs', 'lov', 'ove']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "120a2db1-b6d0-4702-bd04-42ab4937bd81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         135309\n",
       "1         135310\n",
       "2         135311\n",
       "3         135312\n",
       "4         135313\n",
       "           ...  \n",
       "165373    300682\n",
       "165374    300683\n",
       "165375    300684\n",
       "165376    300685\n",
       "165377    300686\n",
       "Name: ID, Length: 165378, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id = test_df['ID']\n",
    "id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "47299a4b-5177-48fa-9106-5647674128b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df[['url_len', 'title_len', 'text_lemm', 'stop_count_title', 'lemm_url', 'stop_count_url',]]\n",
    "test_pool = Pool(data=test_df, text_features=['text_lemm', 'lemm_url',])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "23f778aa-db0d-4de7-a788-d88e89458430",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['label'] = model.predict(test_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "17c7ec8a-b659-4f9f-84ae-0ec8b3667475",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = pd.merge(test_df, id, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c9013398-a3e6-495c-93d5-e220a298c76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: ml_baseline.csv: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "answer[['ID', 'label']].to_csv('test_pred.csv', index=False)\n",
    "\n",
    "!cat ml_baseline.csv | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c344f1a-41b6-4410-8539-98dde1b8c0af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
